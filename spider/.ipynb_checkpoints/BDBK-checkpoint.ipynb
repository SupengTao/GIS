{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_path = './all_city.txt'\n",
    "# river_path = './river.txt'\n",
    "# school_path = './all_school.txt'\n",
    "# spot_path = './all_spot.txt'\n",
    "country_path ='./all_country.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citys():\n",
    "    citys = []\n",
    "    with open (city_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            citys.extend(line.split())\n",
    "    return citys\n",
    "def get_rivers():\n",
    "    rivers = []\n",
    "    with open(river_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            rivers.extend(line.split('、'))\n",
    "    return rivers\n",
    "\n",
    "def get_schools():\n",
    "    schools = []\n",
    "    with open (school_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            schools.extend(line.split())\n",
    "    return schools\n",
    "def get_spots():\n",
    "    spots = []\n",
    "    with open (spot_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            spots.extend(line.split())\n",
    "    return spots\n",
    "def get_countrys():\n",
    "    countrys = []\n",
    "    with open (country_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            countrys.extend(line.split())\n",
    "    return countrys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citys = get_citys()\n",
    "# rivers = get_rivers()\n",
    "# schools = get_schools()\n",
    "start_url = 'https://baike.baidu.com/item/'\n",
    "# city_urls = [start_url + city for city in citys]\n",
    "# river_urls = [start_url + river for river in rivers]\n",
    "# school_urls = [start_url + school for school in schools]\n",
    "# spot_urls = [start_url + spot for spot in all_spots]\n",
    "country = get_countrys()\n",
    "country_url = [start_url + c for c in country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.10 Safari/537.36'}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url, headers):\n",
    "    try:\n",
    "        r = requests.get(url,headers = headers)\n",
    "        r.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    else:\n",
    "        html = r.text.encode(r.encoding).decode()\n",
    "        soup = BeautifulSoup(html,'lxml')\n",
    "        name = soup.find_all('dt',class_= 'basicInfo-item name')\n",
    "        values = soup.find_all('dd',class_= 'basicInfo-item value')\n",
    "        names = list(map(lambda key:key.text.replace('\\xa0',''), name))\n",
    "        values = list(map(lambda value: re.sub('\\\\n\\[.*]', '',value.text.strip()), values))\n",
    "        data = list(zip(names, values))\n",
    "        data = {name:value for name, value in data}\n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_country_data = []\n",
    "for idx, url in enumerate(country_url):\n",
    "    data = get_data(url, headers)\n",
    "    all_country_data.append(data)\n",
    "    print(\"finish {}\\{}\".format(idx, len(all_country_data)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def data2json(data,prefix):\n",
    "    data_json = json.dumps(data,ensure_ascii=False)\n",
    "    json.dump(data_json,open('./{}_data.json'.format(prefix), 'w'))\n",
    "def json2data(prefix):\n",
    "    data_json = json.load(open('./{}_data.json'.format(prefix)))\n",
    "    return json.loads(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for relaiton extraction\n",
    "# spot2city = {}\n",
    "# for city in city_data:\n",
    "#     try:\n",
    "#         spots = city.get('著名景点').split('、')[:-1]\n",
    "#         for spot in spots:\n",
    "#             spot2city[spot] = city.get('中文名称')\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实体1， 实体2， 关系， 种类1， 种类2\n",
    "# relation1 = '位于'\n",
    "# relation2 = '著名景点'\n",
    "# type1 = '景点'\n",
    "# type2 = '城市'\n",
    "# relation_path1 = './spot_city_relation.txt'\n",
    "# relation_path2 = './city_spot_relation.txt'\n",
    "# f1 = open(relation_path1, 'w')\n",
    "# f2 = open(relation_path2, 'w')\n",
    "# for spot in all_spot:\n",
    "#     try:\n",
    "#         city = spot2city[spot]\n",
    "#         if '中山' in city or '威海' in city or '，' in spot or ',' in spot:\n",
    "#             print(spot)\n",
    "#             continue\n",
    "#         f1.write(\"{},{},{},{},{}\\n\".format(spot,city,relation1,type1,type2))\n",
    "#         f2.write(\"{},{},{},{},{}\\n\".format(city,spot,relation2,type2,type1))\n",
    "#     except:\n",
    "#         print(city)\n",
    "# f1.close()\n",
    "# f2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
